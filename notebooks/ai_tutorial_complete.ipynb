{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Tutorial by AI - Complete Introduction\n",
    "\n",
    "Welcome to this comprehensive AI/Machine Learning tutorial! This notebook covers the fundamentals of AI and ML with hands-on examples.\n",
    "\n",
    "## What You'll Learn\n",
    "1. **Python for Data Science** - NumPy, Pandas, and data manipulation\n",
    "2. **Data Visualization** - Creating compelling charts and plots\n",
    "3. **Machine Learning** - Classification, regression, and clustering\n",
    "4. **Neural Networks** - Understanding deep learning basics\n",
    "\n",
    "## Prerequisites\n",
    "- Basic Python knowledge\n",
    "- Curiosity about AI and machine learning!\n",
    "\n",
    "Let's start by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully! üéâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python for Data Science Basics\n",
    "\n",
    "Let's start with NumPy and Pandas fundamentals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy arrays - the foundation of data science\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\"NumPy Array:\", arr)\n",
    "print(\"Matrix Shape:\", matrix.shape)\n",
    "print(\"Array Mean:\", np.mean(arr))\n",
    "print(\"Array Standard Deviation:\", np.std(arr))\n",
    "\n",
    "# Mathematical operations\n",
    "print(\"\\nMathematical Operations:\")\n",
    "print(\"Squared:\", arr ** 2)\n",
    "print(\"Greater than 3:\", arr > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrames - for structured data\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'Age': [25, 30, 35, 28],\n",
    "    'City': ['New York', 'London', 'Tokyo', 'Paris'],\n",
    "    'Salary': [50000, 60000, 70000, 55000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Sample DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Average Age: {df['Age'].mean():.1f}\")\n",
    "print(f\"Max Salary: ${df['Salary'].max():,}\")\n",
    "\n",
    "# Filtering data\n",
    "high_earners = df[df['Salary'] > 55000]\n",
    "print(\"\\nHigh earners (>$55,000):\")\n",
    "print(high_earners[['Name', 'Salary']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Visualization\n",
    "\n",
    "Let's load some sample data and create visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample datasets\n",
    "try:\n",
    "    classification_df = pd.read_csv('sample_data/classification_sample.csv')\n",
    "    regression_df = pd.read_csv('sample_data/regression_sample.csv')\n",
    "    print(\"Sample data loaded successfully!\")\n",
    "    print(f\"Classification data shape: {classification_df.shape}\")\n",
    "    print(f\"Regression data shape: {regression_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Sample data not found. Creating sample data...\")\n",
    "    # Create sample data if not found\n",
    "    n_samples = 1000\n",
    "    feature1 = np.random.normal(0, 1, n_samples)\n",
    "    feature2 = np.random.normal(0, 1, n_samples)\n",
    "    target = (feature1 + feature2 > 0).astype(int)\n",
    "    \n",
    "    classification_df = pd.DataFrame({\n",
    "        'feature1': feature1,\n",
    "        'feature2': feature2,\n",
    "        'target': target\n",
    "    })\n",
    "    \n",
    "    x = np.linspace(0, 10, 200)\n",
    "    y = 2 * x + 1 + np.random.normal(0, 1, 200)\n",
    "    \n",
    "    regression_df = pd.DataFrame({\n",
    "        'x': x,\n",
    "        'y': y\n",
    "    })\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nClassification Data:\")\n",
    "print(classification_df.head())\n",
    "print(\"\\nRegression Data:\")\n",
    "print(regression_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization examples\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Data Visualization Examples', fontsize=16)\n",
    "\n",
    "# Scatter plot of classification data\n",
    "axes[0, 0].scatter(classification_df['feature1'], classification_df['feature2'], \n",
    "                   c=classification_df['target'], cmap='viridis', alpha=0.6)\n",
    "axes[0, 0].set_title('Classification Data')\n",
    "axes[0, 0].set_xlabel('Feature 1')\n",
    "axes[0, 0].set_ylabel('Feature 2')\n",
    "\n",
    "# Line plot of regression data\n",
    "axes[0, 1].scatter(regression_df['x'], regression_df['y'], alpha=0.6)\n",
    "axes[0, 1].set_title('Regression Data')\n",
    "axes[0, 1].set_xlabel('X')\n",
    "axes[0, 1].set_ylabel('Y')\n",
    "\n",
    "# Histogram of feature1\n",
    "axes[1, 0].hist(classification_df['feature1'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('Distribution of Feature 1')\n",
    "axes[1, 0].set_xlabel('Feature 1')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot by target class\n",
    "classification_df.boxplot(column='feature1', by='target', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Feature 1 by Target Class')\n",
    "axes[1, 1].set_xlabel('Target Class')\n",
    "axes[1, 1].set_ylabel('Feature 1')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning Fundamentals\n",
    "\n",
    "Now let's build and train machine learning models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for machine learning\n",
    "X = classification_df[['feature1', 'feature2']]\n",
    "y = classification_df['target']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "print(f\"Target classes: {sorted(y.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train different models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "# Compare model performance\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "for name, accuracy in results.items():\n",
    "    print(f\"{name}: {accuracy:.3f}\")\n",
    "\n",
    "best_model = max(results, key=results.get)\n",
    "print(f\"\\nBest model: {best_model} with accuracy: {results[best_model]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Model comparison bar plot\n",
    "plt.subplot(1, 2, 1)\n",
    "model_names = list(results.keys())\n",
    "accuracies = list(results.values())\n",
    "bars = plt.bar(model_names, accuracies, color=['skyblue', 'lightgreen'])\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add accuracy labels on bars\n",
    "for bar, accuracy in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{accuracy:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Decision boundary visualization\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Use the best model to create decision boundary\n",
    "best_model_obj = models[best_model]\n",
    "\n",
    "# Create a mesh\n",
    "h = 0.02\n",
    "x_min, x_max = X['feature1'].min() - 1, X['feature1'].max() + 1\n",
    "y_min, y_max = X['feature2'].min() - 1, X['feature2'].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# Make predictions on the mesh\n",
    "mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = best_model_obj.predict(mesh_points)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.contourf(xx, yy, Z, alpha=0.8, cmap='RdYlBu')\n",
    "scatter = plt.scatter(X_test['feature1'], X_test['feature2'], c=y_test, \n",
    "                     cmap='RdYlBu', edgecolors='black')\n",
    "plt.colorbar(scatter)\n",
    "plt.title(f'Decision Boundary\\n{best_model}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Networks Introduction\n",
    "\n",
    "Let's explore the basics of neural networks and implement a simple one from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize activation functions\n",
    "x = np.linspace(-5, 5, 100)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(x, sigmoid(x), 'b-', linewidth=2, label='Sigmoid')\n",
    "plt.title('Sigmoid Activation Function')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(x, tanh(x), 'r-', linewidth=2, label='Tanh')\n",
    "plt.title('Tanh Activation Function')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(x, relu(x), 'g-', linewidth=2, label='ReLU')\n",
    "plt.title('ReLU Activation Function')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Activation functions are crucial for neural networks!\")\n",
    "print(\"- Sigmoid: Good for binary classification output\")\n",
    "print(\"- Tanh: Zero-centered, good for hidden layers\")\n",
    "print(\"- ReLU: Most popular for hidden layers, simple and effective\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple neural network implementation\n",
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
    "        # Initialize weights randomly\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.1\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.1\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_history = []\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -250, 250)))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Forward propagation\n",
    "        output = self.forward(X)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = -np.mean(y * np.log(output + 1e-15) + (1 - y) * np.log(1 - output + 1e-15))\n",
    "        self.loss_history.append(loss)\n",
    "        \n",
    "        # Backward propagation\n",
    "        dZ2 = output - y\n",
    "        dW2 = (1/m) * np.dot(self.a1.T, dZ2)\n",
    "        db2 = (1/m) * np.sum(dZ2, axis=0, keepdims=True)\n",
    "        \n",
    "        dA1 = np.dot(dZ2, self.W2.T)\n",
    "        dZ1 = dA1 * self.a1 * (1 - self.a1)\n",
    "        dW1 = (1/m) * np.dot(X.T, dZ1)\n",
    "        db1 = (1/m) * np.sum(dZ1, axis=0, keepdims=True)\n",
    "        \n",
    "        # Update weights\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return (output > 0.5).astype(int)\n",
    "\n",
    "print(\"Simple Neural Network class defined!\")\n",
    "print(\"This network has:\")\n",
    "print(\"- Input layer: Takes features\")\n",
    "print(\"- Hidden layer: Processes information\")\n",
    "print(\"- Output layer: Makes predictions\")\n",
    "print(\"- Sigmoid activation: For smooth gradients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our neural network\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features for better training\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train neural network\n",
    "nn = SimpleNeuralNetwork(input_size=2, hidden_size=5, output_size=1, learning_rate=0.1)\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "y_train_reshaped = y_train.values.reshape(-1, 1)\n",
    "\n",
    "print(\"Training neural network...\")\n",
    "for epoch in range(epochs):\n",
    "    loss = nn.train_step(X_train_scaled, y_train_reshaped)\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "train_predictions = nn.predict(X_train_scaled)\n",
    "test_predictions = nn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = np.mean(train_predictions.flatten() == y_train)\n",
    "test_accuracy = np.mean(test_predictions.flatten() == y_test)\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize neural network training results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(nn.loss_history)\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.subplot(1, 3, 2)\n",
    "h = 0.02\n",
    "x_min, x_max = X_train_scaled[:, 0].min() - 1, X_train_scaled[:, 0].max() + 1\n",
    "y_min, y_max = X_train_scaled[:, 1].min() - 1, X_train_scaled[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = nn.forward(mesh_points)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, levels=50, alpha=0.8, cmap='RdYlBu')\n",
    "scatter = plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], c=y_train, \n",
    "                     cmap='RdYlBu', edgecolors='black')\n",
    "plt.colorbar(scatter)\n",
    "plt.title('Neural Network Decision Boundary')\n",
    "plt.xlabel('Feature 1 (scaled)')\n",
    "plt.ylabel('Feature 2 (scaled)')\n",
    "\n",
    "# Compare all models\n",
    "plt.subplot(1, 3, 3)\n",
    "all_results = results.copy()\n",
    "all_results['Neural Network'] = test_accuracy\n",
    "\n",
    "model_names = list(all_results.keys())\n",
    "accuracies = list(all_results.values())\n",
    "colors = ['skyblue', 'lightgreen', 'lightcoral']\n",
    "\n",
    "bars = plt.bar(model_names, accuracies, color=colors)\n",
    "plt.title('All Models Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "for bar, accuracy in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{accuracy:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Neural network training visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "Congratulations! üéâ You've completed this comprehensive AI tutorial. Here's what you've learned:\n",
    "\n",
    "### Key Concepts Covered:\n",
    "1. **Python for Data Science**: NumPy arrays, Pandas DataFrames, data manipulation\n",
    "2. **Data Visualization**: Creating informative plots with matplotlib and seaborn\n",
    "3. **Machine Learning**: Classification algorithms, model evaluation, decision boundaries\n",
    "4. **Neural Networks**: Forward/backward propagation, activation functions, training process\n",
    "\n",
    "### What You Can Do Next:\n",
    "- üî¨ **Experiment**: Try different datasets and parameters\n",
    "- üìö **Learn More**: Explore deep learning frameworks like TensorFlow or PyTorch\n",
    "- üèóÔ∏è **Build Projects**: Create your own AI applications\n",
    "- üåê **Join Communities**: Participate in Kaggle competitions or AI forums\n",
    "- üìñ **Advanced Topics**: Study CNNs for images, RNNs for sequences, or Transformers for NLP\n",
    "\n",
    "### Resources for Continued Learning:\n",
    "- **Online Courses**: Coursera, edX, Udacity AI courses\n",
    "- **Books**: \"Hands-On Machine Learning\" by Aur√©lien G√©ron\n",
    "- **Datasets**: Kaggle, UCI ML Repository, Google Dataset Search\n",
    "- **Practice**: Work on real-world projects and build a portfolio\n",
    "\n",
    "Remember: The best way to learn AI is by doing! Keep experimenting and building. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final celebration!\n",
    "print(\"üéâ CONGRATULATIONS! üéâ\")\n",
    "print(\"You've successfully completed the AI Tutorial by AI!\")\n",
    "print(\"\")\n",
    "print(\"üìä Models you've learned:\")\n",
    "for name, accuracy in all_results.items():\n",
    "    print(f\"   ‚Ä¢ {name}: {accuracy:.1%} accuracy\")\n",
    "print(\"\")\n",
    "print(\"üöÄ You're now ready to explore the exciting world of AI!\")\n",
    "print(\"Keep learning, keep building, and keep pushing the boundaries of what's possible!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}